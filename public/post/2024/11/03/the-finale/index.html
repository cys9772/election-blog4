<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>The Finale | A minimal Hugo website</title>
    <link rel="stylesheet" href="/css/style.css" />
    <link rel="stylesheet" href="/css/fonts.css" />
    
  </head>

  <body>
    <nav>
    <ul class="menu">
      
      <li><a href="/">Home</a></li>
      
      <li><a href="/about/">About</a></li>
      
      <li><a href="/categories/">Categories</a></li>
      
      <li><a href="/tags/">Tags</a></li>
      
      <li><a href="/index.xml">Subscribe</a></li>
      
    </ul>
    <hr/>
    </nav>

<div class="article-meta">
<h1><span class="title">The Finale</span></h1>
<h2 class="author">Chris S</h2>
<h2 class="date">2024/11/03</h2>
</div>

<main>
<p><em>This blog is an ongoing assignment for Gov 1347: Election Analytics, a course at Harvard College taught by Professor <a href="https://www.ryandenos.com/">Ryan Enos</a>. It will be updated weekly and culminate in a predictive model of the 2024 presidential election.</em></p>
<h2 id="so-the-time-has-come">So, the time has come&hellip;</h2>
<p>After weeks of diving into the mechanics of elections &ndash; <strong>from economic trends to ground game tactics, from polling swings to those elusive &ldquo;October surprises&rdquo;, and even shark attacks</strong> &ndash; it’s finally time to put our analysis to the test. The big question on everyone&rsquo;s mind is: <strong>what’s our prediction?</strong></p>
<p>As we wrap up this journey, I think back to a classic saying that echoes through every stats class &ndash; <strong>&ldquo;All models are wrong, but some are useful.&rdquo;</strong></p>
<p>In other words, no prediction tool is perfect, but with the right approach, <strong>we might just capture some meaningful insights.</strong> So, while no model can account for every quirk and curveball, I&rsquo;m excited to share my final forecast for this election. <em>Maybe it&rsquo;s right. Maybe not.</em></p>
<p>Regardless, let&rsquo;s dive in and see what our analysis reveals!</p>
<h2 id="the-final-model">The Final Model</h2>
<p>In our previous blog, we discussed not only the <strong>influence of shocks</strong> but also decided on a final model we would use. This model hinges on <strong>ANES data, economic factors, and random forest computation</strong> to produce its results.</p>
<p>Before we dig in, let&rsquo;s take a look at the <strong>feature importance:</strong></p>
<img src="https://example.org/post/2024/11/03/the-finale/index_files/figure-html/unnamed-chunk-3-1.png" width="672" />
<p>Interestingly, we can see how the random forest model is <strong>relying heavily on polling data</strong>, which can be positive as it <strong>reveals recent voter sentiment,</strong> but also may not fully capture economic shocks. However, by weighting polling data heavily, the model is <strong>well-suited for situations where the electorate&rsquo;s final preferences align with polling trends.</strong> Further, while economic factors have lower importance, the model is still considering its background influence, <strong>providing a baseline for voter sentiment.</strong></p>
<p>Throughout my research and investigation, I&rsquo;ve found that voter sentiment and economic well-being <strong>significantly impact how voters feel about the incumbent party and potential candidates.</strong> When the economy is doing well, voters tend to feel more secure and may <strong>attribute positive economic outcomes to the current administration or the incumbent party.</strong> On the other hand, economic downturns or periods of high unemployment can <strong>lead to dissatisfaction with the incumbent and voters looking for change.</strong></p>
<p>More broadly, we can see this central idea in political science as the <strong>retrospective voting theory,</strong> suggesting that voters <strong>make decisions based on the past performance of a candidate or party</strong> – economic conditions are just one measure of this performance.</p>
<p>Historically, we&rsquo;ve seen this phenomenon play out. In the <strong>1980 election between Carter and Reagan</strong>, we saw how high inflation and unemployment caused voters to be <strong>frustrated with President Carter,</strong> contributing to a landslide victory for Reagan.</p>
<p>Similarly, <strong>the 1992 election between Bush and Clinton saw the catchphrase “It&rsquo;s the economy, stupid”</strong> as the central statement for Clinton&rsquo;s campaign, highlighting the <strong>recession that affected Bush&rsquo;s approval.</strong> In particular, economic factors like <strong>unemployment and GDP growth were especially divisive,</strong> leading voters to seek an alternative candidate.</p>
<p>Ultimately, by combining ANES data with economic indicators, the model can <strong>account for both personal factors (such as demographics and political attitudes) and external, quantifiable economic conditions</strong> that influence elections and voter sentiment.</p>
<p>And so, let&rsquo;s take a look at the <strong>2024 prediction results</strong> before further analysis and investigation:</p>
<pre><code>## Predicted Vote Shares for 2024 Election:
</code></pre>
<pre><code>## Democratic candidate (Harris): 52.88 %
</code></pre>
<pre><code>## Republican candidate (Trump): 47.72 %
</code></pre>
<p>Here, we can see how Harris leads with a small advantages, but the estimates <strong>still imply a fairly narrow margin,</strong> highlighting the competitiveness of this presidential race. The <strong>small increase in predicted vote share for Harris</strong> compared to previous models  makes sense as economic data like GDP, unemployment rate, CPI, and the S&amp;P <strong>favor the incumbent party when the economy is doing well.</strong></p>
<p>To further investigate our model, I conducted <strong>a cross-validation test</strong> that produced surprising results:</p>
<pre><code>## Random Forest 
## 
## 448 samples
##  28 predictor
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold) 
## Summary of sample sizes: 404, 404, 402, 403, 402, 404, ... 
## Resampling results:
## 
##   RMSE         Rsquared   MAE         
##   0.003043932  0.9999996  0.0009377337
## 
## Tuning parameter 'mtry' was held constant at a value of 9
## Tuning
##  parameter 'splitrule' was held constant at a value of variance
## 
## Tuning parameter 'min.node.size' was held constant at a value of 5
</code></pre>
<pre><code>## [1] &quot;Cross-validated RMSE: 0.00304393235350963&quot;
</code></pre>
<pre><code>## [1] &quot;Cross-validated R-squared: 0.999999560925517&quot;
</code></pre>
<p>Interestingly, we can see an <strong>R-squared value of nearly 1,</strong> suggesting that the model has a <strong>near-perfect explanatory power</strong> over the training data. However, this indicates potential overfitting and whether the model is <strong>simply capturing the “noise” of the dataset.</strong></p>
<p>Thus, my next steps will be to ensure its reliability by conducting <strong>in-sample, out-sample of sample, and bootstrapped prediction estimates</strong> to further evaluate the precision of my model.</p>
<p>Let&rsquo;s dive in!</p>
<h2 id="in-sample-and-out-of-sample-tests">In-Sample and Out-of-Sample Tests</h2>
<p>We&rsquo;ll start with an in-sample test, whereby the model is <strong>evaluated on the same data it was trained on,</strong> which usually produces lower error but <strong>may not reflect the true predictive power on new data:</strong></p>
<pre><code>## In-Sample RMSE: 0.0006174325
</code></pre>
<p>Here, we can see that an extremely low RMSE means that <strong>the model fits the training data extremely well,</strong> but also means that there is <strong>some potential overfitting.</strong> This happens when the model is adjusted too precisely to historical patterns, which may not hold for future data.</p>
<p>Let&rsquo;s see if this <strong>remains true for an out-of-sample test,</strong> in which the model is evaluated on data it hasn&rsquo;t seen, such as <strong>holding out certain data points</strong> to provide a better assessment of how it might perform on new data:</p>
<pre><code>## Training RMSE (excluding 2008 and 2012): 0.0006013352
</code></pre>
<pre><code>## Pseudo-Test RMSE (2008 and 2012): 2.430502
</code></pre>
<p>I chose not to test the model on the two most recent elections (2016 and 2020) <strong>due to the presence of unique factors.</strong> In particular, the political polarization of 2016 and the global pandemic in 2020 heavily influenced the election environment, <strong>which may suggest that the model does more poorly than in reality.</strong></p>
<p>Regardless, we can see the large difference between the Training RMSE and the Pseudo-Test RMSE, highlighting <strong>the model’s high accuracy on the training set but its inability to handle variations in real-world election conditions.</strong> At the same time, the 2008 and 2012 elections <strong>posed interesting factors,</strong> with Barack Obama as the first African American presidential nominee for a major party in 2008 and the 2012 election with the 2008 financial crisis still in its rearview mirror.</p>
<p>Thus, the model <strong>may not be flexible enough to account for these unusual election dynamics,</strong> which could explain the high error.</p>
<p>Let&rsquo;s repeat our analysis to <strong>generate a prediction interval:</strong></p>
<h2 id="the-predictive-interval">The Predictive Interval</h2>
<pre><code>## Predicted Vote Share for 2024:
</code></pre>
<pre><code>## Mean Prediction: 52.81 %
</code></pre>
<pre><code>## 95% Prediction Interval: 52.77 % to 52.85 %
</code></pre>
<p>The 95% prediction interval is extremely narrow, <strong>spanning only 0.08 percentage points (from 52.77% to 52.85%).</strong> Thus, this suggests that there is <strong>very little variability in the model’s predicted outcomes.</strong> At the same time, we need to consider <strong>potential overconfidence and how election outcomes often vary due to last-minute shifts</strong> in voter sentiment and unpredictable factors.</p>
<p>As we&rsquo;ve seen before, there are potential questions about overfitting, and <strong>so the lack of flexibility in the model could mean that it is highly deterministic,</strong> focusing heavily on a few key predictors.</p>
<p>We can also visualize these replications in a histogram:</p>
<img src="https://example.org/post/2024/11/03/the-finale/index_files/figure-html/unnamed-chunk-9-1.png" width="672" />
<p>Ultimately, the narrow 95% prediction interval <strong>suggests strong confidence in this specific outcome,</strong> but may not fully account for <strong>real-world uncertainties and sudden shifts that characterize, or perhaps plague, elections.</strong></p>
<h2 id="now-we-wait">Now We Wait&hellip;</h2>
<p>With election night just 24 hours away, <strong>the world sits on the edge of their seats</strong> (or perhaps their couches), anxiously awaiting the results. I know I&rsquo;ll be glued to the TV.</p>
<p>For weeks, <strong>we&rsquo;ve uncovered the dynamics of this election</strong> &ndash; from the economic climate to voter sentiment, from polls to historical trends. Yet, even with the most advanced model at our fingertips, <strong>one thing remains certain &ndash; elections are full of surprises.</strong></p>
<p>Either way, this process reminds us of the power and limits of data-driven insights. <strong>Ultimately, every vote and every voice counts.</strong> So, now we wait&hellip;</p>
<h2 id="data-sources">Data Sources:</h2>
<p>Data are from the GOV 1347 course materials. All files can be found <a href="https://github.com/cys9772/election-blog4">here</a>. All external sources are hyperlinked.</p>

</main>

  <footer>
  <link rel="stylesheet" href="//cdn.jsdelivr.net/npm/katex/dist/katex.min.css">
<script src="//cdn.jsdelivr.net/combine/npm/katex/dist/katex.min.js,npm/katex/dist/contrib/auto-render.min.js,npm/@xiee/utils/js/render-katex.js" defer></script>

<script src="//cdn.jsdelivr.net/npm/@xiee/utils/js/center-img.min.js" defer></script>

  
  <hr/>
  © <a href="https://yihui.org">Yihui Xie</a> 2017 &ndash; 2024 | <a href="https://github.com/yihui">Github</a> | <a href="https://twitter.com/xieyihui">Twitter</a>
  
  </footer>
  </body>
</html>


<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Final Reflection | A minimal Hugo website</title>
    <link rel="stylesheet" href="/css/style.css" />
    <link rel="stylesheet" href="/css/fonts.css" />
    
  </head>

  <body>
    <nav>
    <ul class="menu">
      
      <li><a href="/">Home</a></li>
      
      <li><a href="/about/">About</a></li>
      
      <li><a href="/categories/">Categories</a></li>
      
      <li><a href="/tags/">Tags</a></li>
      
      <li><a href="/index.xml">Subscribe</a></li>
      
    </ul>
    <hr/>
    </nav>

<div class="article-meta">
<h1><span class="title">Final Reflection</span></h1>
<h2 class="author">Chris S</h2>
<h2 class="date">2024/11/17</h2>
</div>

<main>
<p><em>This blog is an ongoing assignment for Gov 1347: Election Analytics, a course at Harvard College taught by Professor <a href="https://www.ryandenos.com/">Ryan Enos</a>. It will be updated weekly and culminate in a predictive model of the 2024 presidential election.</em></p>
<h2 id="introduction----how-did-our-election-model-fare-what-insights-did-we-capture-and-where-did-we-miss-the-mark">Introduction &ndash; How did our election model fare? <em>What insights did we capture</em>, and where did we miss the mark?</h2>
<p>Election season has come and gone, and now it’s time for the real question – <strong>how did our model stack up against reality?</strong> From economic trends to ground game tactics, polling swings to those elusive “October surprises”, and even shark attacks, <strong>we&rsquo;ve aimed to capture the heart of 2024’s electoral landscape</strong> throughout the last couple of weeks.</p>
<p>As we begin our final reflection, I remember the important quote that echoes throughout almost any statistics course – <strong>“All models are wrong, but some are useful.”</strong> Even in the words of Professor Enos, he writes that the importance of forecasting is so that <strong>“…we can learn about important things…”</strong></p>
<p>No model can be flawless, but we&rsquo;re calling it a win <strong>if it got us even close to the truth.</strong> So, let&rsquo;s dive into the final results and see how well we did. Did our predictions hold up? Let&rsquo;s find out!</p>
<p>And as always, <strong>we&rsquo;ll start with the data…</strong></p>
<h2 id="lets-take-a-step-back">Let&rsquo;s take a step back&hellip;</h2>
<p>Before we get into the actual results, let&rsquo;s do a brief recap of our final predictive model, which hinged on <strong>ANES data, economic factors, and random forest computation</strong> to produce its results.</p>
<p>After analyzing feature importance, we found that our model <strong>relied heavily on polling data</strong>, which offers a real-time snapshot of voter sentiment <strong>but might miss economic shocks that shift the mood more gradually.</strong> Our polling-focused approach is useful when the electorate&rsquo;s final choices <strong>mirror polling trends,</strong> and while economic factors are weighted less, they still <strong>set a baseline for understanding overall voter sentiment.</strong></p>
<p>Through my research, I found that economic well-being deeply shapes how voters feel about incumbents. Strong economic conditions generally <strong>benefit the current administration</strong>, as voters attribute their security to the status quo. In contrast, economic downturns often lead to <strong>a desire for change.</strong> More abstractly, this aligns with <strong>retrospective voting theory,</strong> suggesting that voters base decisions on past performance—where the economy plays a key role.</p>
<p>We&rsquo;ve seen this dynamic before. In the 1980 election, <strong>high inflation and unemployment</strong> led to voter frustration with President Carter, helping Reagan win by a landslide. Similarly, in 1992, Clinton&rsquo;s “It&rsquo;s the economy, stupid” slogan <strong>highlighted a recession that hurt Bush&rsquo;s approval</strong>, and so economic issues like unemployment and GDP growth pushed voters to look for a change.</p>
<p>Thus, I decided that by combining ANES data with economic indicators, the model can <strong>account for both personal factors (such as demographics and political attitudes) and external, quantifiable economic conditions</strong> that influence elections and voter sentiment.</p>
<p>Let&rsquo;s take a look at what it said:</p>
<pre><code>## Predicted Vote Shares for 2024 Election:
</code></pre>
<pre><code>## Democratic candidate (Harris): 52.88 %
</code></pre>
<pre><code>## Republican candidate (Trump): 47.72 %
</code></pre>
<p>Here, we can see that the model predicted that Harris would win with a small margin, with even a <strong>small increase in predicted vote share for Harris</strong> compared to previous models once we factored in economic features like GDP, unemployment rate, CPI, and the S&amp;P, which typically <strong>favor the incumbent party when the economy is doing well.</strong></p>
<p>However, I was <strong>still skeptical about the results,</strong> especially as our cross-validation and out-sample tests revealed <strong>sharp differences</strong>. The out-of-sample test was particularly informative, in which the model is evaluated on data it hasn&rsquo;t seen, such as <strong>holding out certain data points</strong> to provide a better assessment of how it might perform on new data.</p>
<p>Let&rsquo;s take a look at the results:</p>
<pre><code>## Random Forest 
## 
## 448 samples
##  28 predictor
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold) 
## Summary of sample sizes: 404, 404, 402, 403, 402, 404, ... 
## Resampling results:
## 
##   RMSE         Rsquared   MAE         
##   0.003043932  0.9999996  0.0009377337
## 
## Tuning parameter 'mtry' was held constant at a value of 9
## Tuning
##  parameter 'splitrule' was held constant at a value of variance
## 
## Tuning parameter 'min.node.size' was held constant at a value of 5
</code></pre>
<pre><code>## [1] &quot;Cross-validated RMSE: 0.00304393235350963&quot;
</code></pre>
<pre><code>## [1] &quot;Cross-validated R-squared: 0.999999560925517&quot;
</code></pre>
<pre><code>## Training RMSE (excluding 2008 and 2012): 0.0006013352
</code></pre>
<pre><code>## Pseudo-Test RMSE (2008 and 2012): 2.430502
</code></pre>
<p>The model’s R-squared value near 1 <strong>suggests it fits the training data almost perfectly</strong>, but this raises concerns about <strong>overfitting,</strong> as it may be capturing noise rather than true predictive patterns. For the out-of-sample tests, I chose <strong>not to test the model on 2016 and 2020</strong> due to unique factors like intense polarization and the pandemic, which could&rsquo;ve skewed the results.</p>
<p>The large gap between <strong>Training RMSE and Pseudo-Test RMSE</strong> further indicates that while the model performs well on training data, <strong>it struggled with real-world election variability.</strong> At the same time, the 2008 and 2012 elections posed interesting factors, with Barack Obama as the first African American presidential nominee for a major party in 2008 and the 2012 election with the 2008 financial crisis still in its rearview mirror.</p>
<p>Thus, the model <strong>may not be flexible enough to account for these unusual election dynamics,</strong> which could explain the high error.</p>
<p>Finally, we completed repeating samples to generate a prediction interval:</p>
<img src="https://example.org/post/2024/11/17/final-reflection/index_files/figure-html/unnamed-chunk-10-1.png" width="672" />
<p>The narrow 95% prediction interval (spanning only ~0.08 percentage points) suggests the <strong>model has high confidence in its outcome,</strong> with little variability in predictions. However, this may indicate overconfidence, as it <strong>doesn&rsquo;t fully account for last-minute voter shifts and unpredictable factors</strong> that often impact elections. This narrow range also suggests that the model may be relying heavily on <strong>a few key predictors,</strong> making it more deterministic and less adaptable to real-world uncertainties.</p>
<h2 id="sohowd-we-do">So&hellip;how&rsquo;d we do?</h2>
<p>With election night in full steam, we gathered eagerly around screens and TVs to watch the US choose its next president. Unfortunately, our model was a bit off, but something tells me <strong>a lot of people didn&rsquo;t see this election swinging the way it did.</strong></p>
<p>Let&rsquo;s take a look at the state-by-state results:</p>
<p><img src="https://example.org/post/2024/11/17/final-reflection/index_files/figure-html/unnamed-chunk-11-1.png" width="672" /><img src="https://example.org/post/2024/11/17/final-reflection/index_files/figure-html/unnamed-chunk-11-2.png" width="672" /></p>
<p>Overall, we observe that <strong>Republicans secured a majority of states across the central and southern U.S.,</strong> while Democrats won in several states along the <strong>coasts and a few areas of the Midwest.</strong> This reflects a familiar pattern of urban-coastal Democratic support contrasted with Republican dominance in more rural and central regions. In a more granular county-level diagnostic, we observe that <strong>Republican support is spread widely across rural areas,</strong> while Democratic victories are concentrated in <strong>urban centers and some specific regions.</strong></p>
<p>The popular vote reflected similar overall results, with the final count <strong>being roughly 51% for Trump and 49% for Harris.</strong> Clearly, our aggressive 52.88% prediction for Harris was off, and so the question is – <strong>what can we learn from it?</strong></p>
<p>One hypothesis points in the direction of <strong>population shifts and inflation.</strong> Let&rsquo;s take a closer look!</p>
<h2 id="population-shifts">Population Shifts?</h2>
<p>The discrepancy that we&rsquo;re seeing between our prediction and the actual outcome could in part be answered by the <strong>recent population shifts and migrations across the United States.</strong> I hypothesize that my inaccuracy stems from its insufficient integration of recent demographic migration trends and their <strong>effects on voter demographics and preferences.</strong></p>
<p>Recent <a href="https://nypost.com/2024/11/09/lifestyle/new-york-california-losing-population-to-sun-belt-census-data/?utm_source=chatgpt.com">sources</a> have reported that there has been a <strong>notable migration from high-tax, traditionally Democratic states</strong> like New York and California to lower-cost, <strong>more business-friendly states such as Texas, Florida, and North Carolina.</strong> As a result, the influx of residents into traditionally Republican-leaning states has led to <strong>increased voter registration and participation,</strong> potentially bolstering Republican vote shares in these areas. At the same time, the outmigration from Democratic strongholds may have <strong>reduced the Democratic voter base in those states</strong>, affecting their overall vote shares.</p>
<p>Let&rsquo;s see if the data reflects similar trends:</p>
<img src="https://example.org/post/2024/11/17/final-reflection/index_files/figure-html/unnamed-chunk-12-1.png" width="672" />
<p>We can see that the <strong>large abundance of red arrows,</strong> especially concentrated in the Midwest, South, and parts of the interior West, suggests a notable shift toward Republican preferences in these areas, which may have <strong>played a significant role in my model’s inaccuracy.</strong> If Democratic-leaning voters moved to states or counties where they remain a minority, it wouldn&rsquo;t substantially shift these areas toward Democrats. However, the loss of these voters in traditionally Democratic urban centers <strong>could lead to a less robust base.</strong></p>
<p>Let&rsquo;s take a more granular analysis of demographic shifts and look at a key battleground state &ndash; <strong>Pennsylvania:</strong></p>
<img src="https://example.org/post/2024/11/17/final-reflection/index_files/figure-html/unnamed-chunk-13-1.png" width="672" />
<p>Here, we can see how <strong>almost all the arrows are red,</strong> indicating a statewide shift toward Republican support across most counties. In general, we&rsquo;re witnessing many individuals <strong>moving out of major urban centers like Philadelphia and Pittsburgh,</strong> traditionally Democratic strongholds, <strong>into suburban and exurban areas.</strong> This shift may dilute Democratic support in urban areas while boosting Republican numbers in counties where these new residents have moved, <strong>especially if these areas traditionally lean Republican, impacting our overall model accuracy.</strong></p>
<p>Thus, altogether I believe that <strong>incorporating real-time migration data</strong> and analyzing its impact on state-level voting behaviors could enhance the model&rsquo;s predictive accuracy in future elections.</p>
<p>There are several ways in which we could quantitatively test my hypothesis on population shifts. For example, I could collect <strong>population change data (2020 to 2024)</strong> by county from sources like the U.S. Census Bureau to <strong>track shifts in voting patterns</strong> (e.g., the percentage change in Republican vs. Democratic vote share). Thus, I could see if counties with significant population increases are more <strong>likely to have shifted toward the Republican vote,</strong> supporting the idea that new residents have impacted local voting dynamics.</p>
<p>If available, I would look into migration data, such as from the <strong>IRS or USPS address data</strong> that can help identify where new residents in each county originated. As a result, I could test <strong>if areas that received large numbers of residents from Democratic-leaning or Republican-leaning regions.</strong></p>
<p>Armed with this new insight and data, <strong>a regression model using predictors like population growth rate, economic factors, and migration patterns</strong> would be more robust at predicting the size of voting shifts toward Republicans or Democrats in each county, and the overall two-party vote share. Additionally, <strong>a time series analysis</strong> could be used to assess whether counties with higher recent migration rates (e.g., 2018-2024) deviated from their <strong>historical voting trends</strong> more than counties with stable populations.</p>
<p>More specifically, this approach would <strong>help to isolate whether recent migration significantly correlates</strong> with the somewhat unexpected voting shifts in the 2024 election.</p>
<h2 id="inflation">Inflation?</h2>
<p>Another pivotal issue that influenced voter behavior was <strong>inflation.</strong> While my model incorporated economic indicators like GDP, unemployment, and CPI, it <strong>did not fully capture the nuanced impact of inflation</strong> on voter sentiment. More specifically, while CPI provides a good overall measure of inflation, <a href="https://www.usatoday.com/story/opinion/columns/2024/11/12/inflation-voters-economic-pain-anger-donald-trump-bureau-labor-statistics-housing-child-care-health/76202853007/">sources</a> have found that voters <strong>continued to express concerns about rising costs in housing and healthcare.</strong></p>
<p>As I reflect on my model, the reliance on historical data may have been limiting, especially when thinking about <strong>the unique economic dynamics of the 2024 cycle post-pandemic.</strong> Pressure from supply chain disruptions and labor unions presented new challenges that <strong>traditional economic indicators may not have been able to capture.</strong> Interestingly, research also indicates that voters often respond more strongly to <a href="https://www.cornellpress.cornell.edu/inflation-the-fed-and-the-2024-us-election/">perceived economic threats than actual statistical indicators</a>. The <strong>persistent anxiety</strong> that inflation creates can erode consumer confidence in the incumbent party and <strong>significantly influence voting behavior.</strong></p>
<p>To test this hypothesis, I would propose <strong>a correlation analysis between inflation and voting patterns</strong> to examine the relationship between inflation rates and voting behavior by <strong>analyzing county-level inflation data alongside voting outcomes.</strong> This would help determine <strong>if areas experiencing higher inflation saw significant shifts in voting patterns.</strong> I could enhance the model by using additional inflation indicators, such as the <strong>Personal Consumption Expenditures (PCE) Price Index</strong>, which may capture consumer spending behaviors <strong>more accurately</strong> than simply CPI. Of course, I would also have to consider overfitting as a potential issue.</p>
<p>Similar to the previous section, <strong>a time-series analysis</strong> could provide meaningful insight into <strong>how changes in inflation over time correlate with shifts in voting patterns.</strong> Similar to out-of-sample tests, I would aim to evaluate the model’s accuracy at <strong>varying inflation levels</strong> to see if it can maintain accuracy without too much difference in RMSE. If so, further model adjustment would be necessary.</p>
<h2 id="final-thoughts-and-model-adjustments">Final Thoughts and Model Adjustments</h2>
<p>As the dust settles on the 2024 election, <strong>we&rsquo;ve come a long way since our first exploratory blog post.</strong> While our final model provided valuable insights, the actual results remind us that <strong>elections are inherently unpredictable.</strong> Factors like population shifts and economic fluctuations, particularly inflation, played significant roles that our model didn&rsquo;t fully anticipate.</p>
<p>As Professor Enos reiterated in class, the core experience of this predictive work <strong>is not simply getting the most accurate result,</strong> but the growth and learning that comes along the way. Moreover, this reflection plays a broader role in underscoring the importance of <strong>continually refining our models</strong> to better capture the complexities of voter behavior. By integrating more dynamic data and accounting for emerging trends, we can hopefully enhance our predictive accuracy in future elections.</p>
<p>In the end, the true essence of democracy lies in the power of each individual&rsquo;s vote, but more broadly, <em>our unique voice.</em> I didn&rsquo;t realize it then, <strong>but I suppose this blog has been an outlet for just that.</strong></p>
<h2 id="data-sources">Data Sources:</h2>
<p>Data are from the GOV 1347 course materials. All files can be found <a href="https://github.com/cys9772/election-blog4">here</a>. All external sources are hyperlinked.</p>

</main>

  <footer>
  <link rel="stylesheet" href="//cdn.jsdelivr.net/npm/katex/dist/katex.min.css">
<script src="//cdn.jsdelivr.net/combine/npm/katex/dist/katex.min.js,npm/katex/dist/contrib/auto-render.min.js,npm/@xiee/utils/js/render-katex.js" defer></script>

<script src="//cdn.jsdelivr.net/npm/@xiee/utils/js/center-img.min.js" defer></script>

  
  <hr/>
  © <a href="https://yihui.org">Yihui Xie</a> 2017 &ndash; 2024 | <a href="https://github.com/yihui">Github</a> | <a href="https://twitter.com/xieyihui">Twitter</a>
  
  </footer>
  </body>
</html>


<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Blog Post -- Shocks, Models, and Possums? | A minimal Hugo website</title>
    <link rel="stylesheet" href="/css/style.css" />
    <link rel="stylesheet" href="/css/fonts.css" />
    
  </head>

  <body>
    <nav>
    <ul class="menu">
      
      <li><a href="/">Home</a></li>
      
      <li><a href="/about/">About</a></li>
      
      <li><a href="/categories/">Categories</a></li>
      
      <li><a href="/tags/">Tags</a></li>
      
      <li><a href="/index.xml">Subscribe</a></li>
      
    </ul>
    <hr/>
    </nav>

<div class="article-meta">
<h1><span class="title">Blog Post &ndash; Shocks, Models, and Possums?</span></h1>
<h2 class="author">Chris S</h2>
<h2 class="date">2024/10/28</h2>
</div>

<main>
<p><em>This blog is an ongoing assignment for Gov 1347: Election Analytics, a course at Harvard College taught by Professor <a href="https://www.ryandenos.com/">Ryan Enos</a>. It will be updated weekly and culminate in a predictive model of the 2024 presidential election.</em></p>
<h2 id="introduction----what-role-do-shocks-play-in-election-results-do-these-apolitical-shocks-actually-play-a-role-or-do-they-simply-make-for-humorous-article-titles">Introduction &ndash; What role do <em>shocks</em> play in election results? Do these <em>apolitical shocks</em> actually play a role, or do they simply make for humorous article titles?</h2>
<p>In politics, experts often talk about <strong>predictability.</strong> For example, a candidate’s popularity <strong>might rise with a strong economy, or perhaps fall after a scandal.</strong> But what about those random, <strong>seemingly apolitical moments</strong> that, for whatever reason, capture the public’s attention and steer a bit of the national conversation? From an unexpected celebrity endorsement to a viral meme, <strong>do these quirky shocks actually shift election results</strong>, or are they just great headlines?</p>
<p>Exploring these “shocks” feels a bit like <strong>chasing down the hidden influences on public opinion</strong> or perhaps they hold the secret ingredient that adds an unexpected twist to a familiar political recipe. So, just <strong>how much do these factors play into elections,</strong> if at all? Or do they simply give us a chance to enjoy a laugh <strong>before getting back into nitty-gritty?</strong></p>
<p>Let&rsquo;s take a closer look.</p>
<h2 id="iconic-election-forecasting">Iconic Election Forecasting</h2>
<p>Before we get into shocks, let&rsquo;s examine <strong>a few legendary (and perhaps unusual)</strong> election forecasting models.</p>
<p>To kick things off, the <a href="https://www.cambridge.org/core/services/aop-cambridge-core/content/view/B256F4EA39F7F9B6F0423BA4EDA46B4A/S1049096524000921a.pdf/iowa-electronic-markets-forecasting-the-2024-us-presidential-election.pdf">Iowa Electronic Markets</a> model used <strong>real-money prediction markets</strong> to predict the 2024 U.S. presidential election. Since its inception in 1988, the IEM has done surprisingly level, <strong>averaging an error rate of roughly 1.34 percentage points.</strong></p>
<p>However, it is quite sensitive to political shifts (like the June 27th debate), <strong>with confidence intervals and prediction rates changing drastically</strong> with a new Democratic nominee as <strong>the market adapted to surprising information.</strong> It also occasionally showed <strong>bimodal distributions,</strong> indicating scenarios with both potential Republican and Democratic wins – <strong>uncommon, but not entirely unprecedented in the context of market forecasts.</strong> Altogether, we&rsquo;re seeing the model predict <strong>a slight Democratic edge in the popular vote,</strong> but maintains substantial uncertainty particularly as voter sentiment continues to shift.</p>
<p>Another iconic model is the <a href="https://www.cambridge.org/core/services/aop-cambridge-core/content/view/EE1A580C166E04F3D34C071AF413A3E1/S104909652400091Xa.pdf/the-challenge-of-forecasting-the-2024-presidential-and-house-elections-economic-pessimism-and-election-outcomes.pdf">Economic Pessimism Model</a>, which <strong>leverages public economic outlook</strong> as a basis for its election outcome predictions. This goes back to our very first post on the idea of fundamentals, like the economy, which has <strong>reflected consistent trends since the 1960s</strong> whereby economic downturns have correlated with incumbent loss. For example, inflationary pressures in the 1980s <strong>contributed to Carter’s loss</strong> while positive growth <strong>helped Reagan in 1984.</strong></p>
<p>The model <strong>currently predicts a small Republican win,</strong> but Lockerbie also recognizes that unforeseen events and circumstances as the election nears can dramatically change voter sentiment. With the race this close, <strong>even the smallest shift</strong> may be the difference between a win and a loss.</p>
<p>The final interesting model is the <a href="https://www.cambridge.org/core/services/aop-cambridge-core/content/view/89476D06B0055BD8B9E4557F09C9D10A/S1049096524000982a.pdf/the-2024-us-presidential-election-possum-poll.pdf">PoSSUM Model</a>. Instead of using state-wide polling or economic data, the authors <strong>analyzed users’ digital traces on social media platforms</strong> like X (formerly Twitter) to compute their predictions. The addition of AI and large language models (LLMs) can help <strong>infer voting preferences and behavior via sentiment analysis</strong> without direct interviews or polling.</p>
<p>By assessing digital profiles, it assigns <em>speculation scores</em> to gauge the <strong>confidence of inferences</strong> about voting preferences. Overall, the model’s results <strong>mirror closely with traditional polls,</strong> suggesting that AI polling and sophisticated algorithms are as good, if not better, than traditional methods.</p>
<p>Altogether, these somewhat unusual models provide <strong>a brief glimpse into the variety and creativity</strong> that political scientists and researchers are exploring when it comes to predicting election outcomes.</p>
<h2 id="apolitical-shocks">Apolitical Shocks</h2>
<p>Before we dive into some final tweaking of our model, let&rsquo;s examine <strong>the common debate over how sudden shocks affect voting behavior.</strong> This first began in <a href="https://muse-jhu-edu.ezp-prod1.hul.harvard.edu/book/64646">Achen and Bartels (2016)</a> which explored the influence of <strong>shark attacks in New Jersey beach towns.</strong> Through their analysis, they uncovered that these towns often <strong>voted significantly less for the incumbent</strong> compared to non-beach towns that weren&rsquo;t facing this surprising shock.</p>
<p>However, research by <a href="https://www-journals-uchicago-edu.ezp-prod1.hul.harvard.edu/doi/pdfplus/10.1086%2F699244">Fowler and Hall (2018)</a> later discovered that <strong>incorporating other counties</strong> as a whole dramatically <strong>reduced</strong> the significance of this unusual shark attack shock. What they found was that Ocean County, the county that Achen and Bartels studied, <strong>was an outlier</strong>, and in reality, beach and non-beach towns voted <strong>rather similarly.</strong></p>
<p>These aren&rsquo;t the only examples of apolitical shocks and their influence. For instance, <a href="https://www-nowpublishers-com.ezp-prod1.hul.harvard.edu/article/Details/QJPS-9057">Healy and Malhotra (2010)</a> found that <strong>whether or not there was a “disaster declaration”</strong> on certain shocking events created different impacts on voting behavior. They argued that such declarations often <strong>amplify incumbent support because they create the impression of a proactive response,</strong> regardless of the disaster&rsquo;s scale or the actual effectiveness of relief efforts.</p>
<p>Together, we can see that while these apolitical shocks provide interesting insights into voting behavior and election outcomes, <strong>their effects feel too context-dependent and may not be generalizable across many states.</strong> Thus, I won&rsquo;t be including this in my final model.</p>
<h2 id="random-forest-tweaks">Random Forest Tweaks</h2>
<p>Of all the models I&rsquo;ve investigated thus far, the random forest&rsquo;s robustness and <strong>ability to do both regression and classification tasks</strong> make it my favorite and most compelling. In particular, I&rsquo;ll be using the <strong>ANES dataset</strong> which provides a rich collection of variables related to voting behavior and demographics to justify this decision.</p>
<p>As we’ve seen, the model’s ability to capture the 2016 election <strong>shows promising results:</strong></p>
<pre><code>## Confusion Matrix and Statistics
## 
##             Reference
## Prediction   Democrat Republican
##   Democrat        774        302
##   Republican      318        694
##                                          
##                Accuracy : 0.7031         
##                  95% CI : (0.683, 0.7226)
##     No Information Rate : 0.523          
##     P-Value [Acc &gt; NIR] : &lt;2e-16         
##                                          
##                   Kappa : 0.4053         
##                                          
##  Mcnemar's Test P-Value : 0.5469         
##                                          
##             Sensitivity : 0.7088         
##             Specificity : 0.6968         
##          Pos Pred Value : 0.7193         
##          Neg Pred Value : 0.6858         
##              Prevalence : 0.5230         
##          Detection Rate : 0.3707         
##    Detection Prevalence : 0.5153         
##       Balanced Accuracy : 0.7028         
##                                          
##        'Positive' Class : Democrat       
## 
</code></pre>
<p>Here, we can see <strong>a strong accuracy of 0.703,</strong> with a 95% confidence interval of <strong>0.683 to 0.7226,</strong> suggesting a fairly robust and confident estimate of the model’s performance. Compared to the <strong>simple random guessing (NIR) rate of 0.523</strong>, we observe that our model performs <strong>significantly better.</strong></p>
<p>Reviewing again, its <strong>out-of-sample accuracy</strong> is just as good:</p>
<pre><code>## Confusion Matrix and Statistics
## 
##             Reference
## Prediction   Democrat Republican
##   Democrat        187         70
##   Republican       85        179
##                                           
##                Accuracy : 0.7025          
##                  95% CI : (0.6612, 0.7415)
##     No Information Rate : 0.5221          
##     P-Value [Acc &gt; NIR] : &lt;2e-16          
##                                           
##                   Kappa : 0.4053          
##                                           
##  Mcnemar's Test P-Value : 0.2608          
##                                           
##             Sensitivity : 0.6875          
##             Specificity : 0.7189          
##          Pos Pred Value : 0.7276          
##          Neg Pred Value : 0.6780          
##              Prevalence : 0.5221          
##          Detection Rate : 0.3589          
##    Detection Prevalence : 0.4933          
##       Balanced Accuracy : 0.7032          
##                                           
##        'Positive' Class : Democrat        
## 
</code></pre>
<p>Thus, we clearly observe how the random forest model <strong>maintains an accuracy of roughly 0.70,</strong> demonstrating how it can consistently capture the complex interactions between education, race, religion, etc.</p>
<p>Based on this, <strong>our previous prediction was:</strong></p>
<pre><code>## [1] 52.21456 48.67542
</code></pre>
<p>Thus, we see that the random forest model predicts a reasonably <strong>narrow gap in vote share,</strong> with Harris leading by a slim margin. Now, we&rsquo;ll <strong>incorporate economic variables</strong> into our model to improve its accuracy and predictive ability.</p>
<p>Research from <a href="https://fairmodel.econ.yale.edu/RAYFAIR/PDF/2018B.htm">Fair (2018)</a> and <a href="https://hollis.harvard.edu/primo-explore/fulldisplay?docid=TN_cdi_jstor_books_j_ctt7ztpn1&amp;context=PC&amp;vid=HVD2&amp;search_scope=everything&amp;tab=everything&amp;lang=en_US">Sides and Vavreck (2013)</a> have shown that the <strong>state of the econom</strong>y has a <strong>non-negligible ability</strong> to mobilize and persuade voters.</p>
<p>Thus, let&rsquo;s take a look at the <strong>updated model&rsquo;s prediction:</strong></p>
<pre><code>## Predicted Vote Shares for 2024 Election:
</code></pre>
<pre><code>## Democratic candidate (Harris): 52.88 %
</code></pre>
<pre><code>## Republican candidate (Trump): 47.72 %
</code></pre>
<p>Here, we can see how the estimates <strong>still imply a fairly narrow margin,</strong> highlighting the competitiveness of this presidential race. We also observe <strong>a very small increase in predicted vote share for Harris,</strong> which makes sense as economic data like GDP, unemployment rate, CPI, and the S&amp;P often <strong>favor the incumbent party when the economy is doing well.</strong></p>
<p>To further cement our prediction, let&rsquo;s do a <strong>cross-validation</strong> to examine the model&rsquo;s precision:</p>
<pre><code>## Random Forest 
## 
## 448 samples
##  28 predictor
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold) 
## Summary of sample sizes: 404, 404, 402, 403, 402, 404, ... 
## Resampling results:
## 
##   RMSE         Rsquared   MAE         
##   0.003043932  0.9999996  0.0009377337
## 
## Tuning parameter 'mtry' was held constant at a value of 9
## Tuning
##  parameter 'splitrule' was held constant at a value of variance
## 
## Tuning parameter 'min.node.size' was held constant at a value of 5
</code></pre>
<pre><code>## [1] &quot;Cross-validated RMSE: 0.00304393235350963&quot;
</code></pre>
<pre><code>## [1] &quot;Cross-validated R-squared: 0.999999560925517&quot;
</code></pre>
<p>Here, we can see an <strong>R-squared value of nearly 1,</strong> suggesting that the model has a <strong>near-perfect explanatory power</strong> over the training data. However, I&rsquo;m also thinking about potential overfitting and whether the model is <strong>simply capturing the “noise” of the dataset.</strong> Then again, the random forest model can reveal non-linear interactions, which may be <strong>well-suited for the current data structure.</strong> My next steps will be to ensure its reliability by <strong>evaluating the model performance on an independent test set,</strong> and considering additional techniques like <strong>feature selection or reducing complexity</strong> if the precision drops significantly.</p>
<p>Altogether, this will make for an exciting model as we gear up for the <strong>final days before Nov 5th.</strong> Stay tuned for the <strong>final results next Monday!</strong></p>
<h2 id="data-sources">Data Sources:</h2>
<p>Data are from the GOV 1347 course materials. All files can be found <a href="https://github.com/cys9772/election-blog4">here</a>. All external sources are hyperlinked.</p>

</main>

  <footer>
  <link rel="stylesheet" href="//cdn.jsdelivr.net/npm/katex/dist/katex.min.css">
<script src="//cdn.jsdelivr.net/combine/npm/katex/dist/katex.min.js,npm/katex/dist/contrib/auto-render.min.js,npm/@xiee/utils/js/render-katex.js" defer></script>

<script src="//cdn.jsdelivr.net/npm/@xiee/utils/js/center-img.min.js" defer></script>

  
  <hr/>
  © <a href="https://yihui.org">Yihui Xie</a> 2017 &ndash; 2024 | <a href="https://github.com/yihui">Github</a> | <a href="https://twitter.com/xieyihui">Twitter</a>
  
  </footer>
  </body>
</html>

